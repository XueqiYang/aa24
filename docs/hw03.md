<a name=top><br>
  <p align=center>&nbsp;<a href="/README.md#top">home</a> ::
  <a href="/docs/syllabus.md#top">syllabus</a> ::
  <a href="https://docs.google.com/spreadsheets/d/16yxmklx4zvmfAHE7QocOQZZ4v4UxD5ktJHWMJEjBcMI/edit#gid=0">groups</a> ::
  <a href="/LICENSE.md#top">&copy;&nbsp;2024</a>, <a href="http:/timm.fyi">Tim Menzies</a><br>
  <a href="/README.md#top"><img width=600  
     src="/etc/img/ase24.png"></a></p>

# Week3


## Task1: Look at Some Data

In a little ascii table in hw/w3, generate a little ascii table that shows the following numbers:

- Have a look at these two data sets:
  - https://github.com/timm/lo/blob/main/data/diabetes.csv
  - https://github.com/timm/lo/blob/main/data/soybean.csv
- Count up how many classes are in each file, and the number of rows for each class.
  - Express that as a percetange of number of rows in those files.

## Task2: Build a Naive Bayes Classifier

- Write Python code that loads the above csv files, creating one DATA objects for the rows of each class.
- Implement the `like()` methods that report:
    - How much a NUM likes a number
      - https://github.com/timm/lo/blob/6jan24/src/gate.lua#L54-L5
    - How much a SYM likes a symbol
      - https://github.com/timm/lo/blob/6jan24/src/gate.lua#L85-L86
    - How much a ROW likes a DATA
      - https://github.com/timm/lo/blob/6jan24/src/gate.lua#L142-L150
- Write a classifier that, given a ROW, it runs around those DATA objects asking "how much do you like me?"
  (and the classification of that ROW is the DATA object that likes it the most).
  - https://github.com/timm/lo/blob/6jan24/src/gate.lua#L130-L138
- Put it all together. Read at least 10 rows then, after than, classify each new ROW **before** update all
  the DATA objects
  - https://github.com/timm/lo/blob/6jan24/src/gate.lua#L401-L408

## Task3: Test on Diabetes

Run this on diabetes.csv. This should return an accuracy of around 72% (give or take). Report
what accuracies you get in hw/w3.


## Task4: Explore low frequency reasoning with Soybean

Write two loops that explore low frequency settings $k \in \{0,1,2,3\}$ and $m \in \{0,1,2,3\}$. And
apply all that to soybean.csv. Report in hw/w3 how the accuracy changes with these $k,m$ differences.
When I do that, I get accuracies from 74% to 85%. Report what you get. Comment on what $k,m$ settings
you'd recommend for diabetes and soybean, and why.


